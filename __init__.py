from .src.install import check_and_install, check_and_install_version
import os


def should_skip_install():
    """
    ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– COMFYUI_IMAGE2PROMPT_SKIP_INSTALL çš„å€¼ã€‚
    æ”¯æŒå¤šç§è¡¨ç¤ºè·³è¿‡å®‰è£…çš„å­—ç¬¦ä¸²ã€‚

    è¿”å›:
    bool: å¦‚æœç¯å¢ƒå˜é‡çš„å€¼è¡¨ç¤ºè·³è¿‡å®‰è£…ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """
    # å®šä¹‰ä¸€ä¸ªé›†åˆï¼ŒåŒ…å«æ‰€æœ‰è¡¨ç¤ºè·³è¿‡å®‰è£…çš„å€¼
    skip_values = {"TRUE", "YES", "1", "SKIP", "Y"}

    # è¯»å–ç¯å¢ƒå˜é‡çš„å€¼ï¼Œå¦‚æœæœªè®¾ç½®åˆ™é»˜è®¤ä¸º "False"
    env_value = os.getenv("COMFYUI_IMAGE2PROMPT_SKIP_INSTALL", "False").upper()

    # åˆ¤æ–­ç¯å¢ƒå˜é‡çš„å€¼æ˜¯å¦åœ¨ skip_values é›†åˆä¸­
    return env_value in skip_values


if not should_skip_install():

    check_and_install("tqdm")

    check_and_install("image-reward", import_name="ImageReward")

    check_and_install_version("Pillow", "10.1.0", import_name="PIL")

    check_and_install_version("huggingface_hub", "0.20.1")

    # 4bit internlm
    # linux must install manually for kernel compile
    check_and_install_version("auto-gptq", "0.7.1", import_name="auto_gptq")

    check_and_install_version("einops", "0.7.0")
    check_and_install("torchvision")
    check_and_install_version("accelerate", "0.25.0")
    check_and_install_version("timm", "0.9.16")

    # >= 4.37.1 Qwen-1.5      
    # >= 4.38.2 deepseek , test ok == 4.37.1
    # >= 4.38.2 llama3
    check_and_install_version("transformers","4.38.2",up_version=False)

    # llama3 4bit or 8bit
    check_and_install_version("accelerate","0.29.3")
    check_and_install_version("bitsandbytes","0.43.1")

    ## Qwen1_8 Prompt
    check_and_install("tiktoken")
    # check_and_install_version("transformers-stream-generator", "0.0.4",import_name="transformers_stream_generator")

    # deepseek
    check_and_install("attrdict")
    check_and_install_version("einops", "0.7.0")
    check_and_install_version("sentencepiece", "0.2.0")
    check_and_install(
        "git+https://github.com/deepseek-ai/DeepSeek-VL.git@86a3096",
        import_name="deepseek_vl",
    )

    # >= 4.37.1 Qwen-1.5
    # >= 4.38.2 deepseek , test ok == 4.37.1
    # check_and_install_version("transformers","4.37.1",up_version=False)

    # youdao Translate
    check_and_install("pycryptodome", import_name="Crypto")
else:
    print("é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡è·³è¿‡Comfyui_image2promptå®‰è£…ä¾èµ–é¡¹æ­¥éª¤")

from .src.image2text import Image2Text, LoadImage2TextModel, Image2TextWithTags
from .src.text2prompt import LoadText2PromptModel,Text2Prompt,Text2GPTPrompt
from .src.tools import Translate2Chinese,ShowText,TextBox
from .src.conditioning import PromptConditioning,AdvancedCLIPTextEncode
from .src.reward import LoadImageRewardScoreModel,ImageRewardScore,ImageBatchToList
from .src.t5_gpt import T5_LLM_Node,QuantizationConfig_Node,Load_T5_LLM_Model

NODE_CLASS_MAPPINGS = {
    "Image2Text": Image2Text,
    "LoadImage2TextModel": LoadImage2TextModel,
    "Image2TextWithTags": Image2TextWithTags,
    "LoadText2PromptModel":LoadText2PromptModel,
    "Text2Prompt":Text2Prompt,
    "Text2GPTPrompt":Text2GPTPrompt,
    "Translate2Chinese|fofo":Translate2Chinese,
    "ShowText|fofo":ShowText,
    "TextBox|fofo":TextBox,
    "CLIP PromptConditioning|fofo":PromptConditioning,
    "CLIP AdvancedTextEncode|fofo":AdvancedCLIPTextEncode,
    "LoadImageRewardScoreModel|fofo":LoadImageRewardScoreModel,
    "ImageRewardScore|fofo":ImageRewardScore,
    "ImageBatchToList|fofo":ImageBatchToList,
    "LoadT5Model|fofo": Load_T5_LLM_Model,
    "T5QuantizationConfig|fofo": QuantizationConfig_Node,
    "T5Text2Prompt|fofo": T5_LLM_Node,
}

# A dictionary that contains the friendly/humanly readable titles for the nodes
NODE_DISPLAY_NAME_MAPPINGS = {
    "Image2Text": "Image to Text ğŸ¼",
    "LoadImage2TextModel": "Loader Image to Text Model ğŸ¼",
    "Image2TextWithTags":"Image to Text with Tags ğŸ¼",
    "LoadText2PromptModel":"Loader Text to Prompt Model ğŸ¼",
    "Text2Prompt":"Text to Prompt ğŸ¼",
    "Text2GPTPrompt":"Multi Text to GPTPrompt ğŸ¼",
    "Translate2Chinese|fofo":"Translate Text to Chinese ğŸ¼",
    "ShowText|fofo":"Show Text ğŸ¼",
    "TextBox|fofo":"Text Box ğŸ¼",
    "CLIP PromptConditioning|fofo":"CLIP Prompt Conditioning ğŸ¼",
    "CLIP AdvancedTextEncode|fofo": "CLIP Advanced Text Encode ğŸ¼",
    "LoadImageRewardScoreModel|fofo":"Load Image Reward Score Model ğŸ¼",
    "ImageRewardScore|fofo":"Image Reward Score ğŸ¼",
    "ImageBatchToList|fofo":"Image Batch to List ğŸ¼",
    "LoadT5Model|fofo": "Load T5 Model ğŸ¼",
    "T5QuantizationConfig|fofo": "T5 Quantization Config ğŸ¼",
    "T5Text2Prompt|fofo": "T5 Text to Prompt ğŸ¼",
}

## model dir
from .src.install import GLOBAL_MODELS_DIR
import os
if not os.path.exists(GLOBAL_MODELS_DIR):
    os.makedirs(GLOBAL_MODELS_DIR,exist_ok=True)



## js file
import folder_paths
import filecmp
import shutil
def copy_js_files():
    javascript_folder = os.path.join(os.path.dirname(os.path.realpath(__file__)), "js")
    extentions_folder = os.path.join(folder_paths.base_path,"web" , "extensions" , "fofo" )
    os.makedirs(extentions_folder,exist_ok=True)
    
    result = filecmp.dircmp(javascript_folder, extentions_folder)
    print(javascript_folder)
    print(extentions_folder)
    if result.left_only or result.diff_files:
        file_list = list(result.left_only)
        file_list.extend(x for x in result.diff_files if x not in file_list)

        for file in file_list:
            src_file = os.path.join(javascript_folder, file)
            dst_file = os.path.join(extentions_folder, file)
            print(src_file,dst_file)
            if os.path.exists(dst_file):
                os.remove(dst_file)
            shutil.copy(src_file, dst_file)
copy_js_files()